{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning:\n",
      "\n",
      "Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections\n",
    "import re\n",
    "#import random\n",
    "#import webbrowser\n",
    "from get_all_tickers import get_tickers as gt\n",
    "import yfinance as yf\n",
    "from yahoo_fin import stock_info as si\n",
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sent_analy import sentiment\n",
    "from nltk.corpus import subjectivity #From the NLTK corpus we will import subjectivity to classify a tweet as subjective/objective.\n",
    "from nltk.sentiment import SentimentAnalyzer #SentimentAnalyzer Library to perform the library\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #Sentiment and Intensity Analyzer will perform our required analysis\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "if not os.path.exists(\"wordcloud_images\"):\n",
    "    os.mkdir(\"wordcloud_images\")\n",
    "api_key='0ce8b6189282441e91727a812dc0f110'\n",
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "from fuzzywuzzy import fuzz\n",
    "from pandas.io.json import json_normalize\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "     \n",
    "    '''Aim is to build a 2D matrix and track the cost or changes required\n",
    "       by comparing each both strings character by character.\n",
    "    ''' \n",
    "    # Initialize the zero matrix  \n",
    "    row_length = len(str1)+1\n",
    "    col_length = len(str2)+1\n",
    "    distance = np.zeros((row_length,col_length),dtype = int)\n",
    "    \n",
    "    # Populate matrix of zeros with the indices of each character of both strings\n",
    "    for i in range(1, row_length):\n",
    "        for k in range(1,col_length):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "            \n",
    "    # writng loops to find the cost of deletion, addition and substitution    \n",
    "    for col in range(1, col_length):\n",
    "        for row in range(1, row_length):\n",
    "            if str1[row-1] == str2[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                cost = 1\n",
    "                \n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of removal\n",
    "                                 distance[row][col-1] + 1,          # Cost of addition\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitution\n",
    "            \n",
    "    distance = distance[row][col]\n",
    "    \n",
    "    return \"The strings are {} edits away\".format(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the helper library from https://www.twilio.com/docs/python/install\n",
    "from twilio.rest import Client\n",
    "\n",
    "\n",
    "# Your Account Sid and Auth Token from twilio.com/console\n",
    "# DANGER! This is insecure. See http://twil.io/secure\n",
    "account_sid = 'ACd8ef206036b5035d7c965903578c758a'\n",
    "auth_token = 'c1daf648b8841705045e3991b576332a'\n",
    "client = Client(account_sid, auth_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Muku_Chat(Chat):\n",
    "\n",
    "    def __init__(self, pairs, reflections={}):\n",
    "\n",
    "        # add `z` because now items in pairs have three elements\n",
    "        self._pairs = [(re.compile(x, re.IGNORECASE), y, z) for (x, y, z) in pairs]\n",
    "        self._reflections = reflections\n",
    "        self._regex = self._compile_reflections()\n",
    "        \n",
    "    def converse(self, quit=\"quit\"):\n",
    "        user_input = \"\"\n",
    "        while user_input != quit:\n",
    "            user_input = quit\n",
    "            try:\n",
    "                user_input = input(\">\")\n",
    "            except EOFError as e:\n",
    "                print(engine.say(e))\n",
    "            if user_input:\n",
    "                while user_input[-1] in \"!.\":\n",
    "                    user_input = user_input[:-1]\n",
    "                print(self.respond(user_input))\n",
    "\n",
    "    def respond(self, str):\n",
    "        for (pattern, response, callback) in self._pairs:\n",
    "            match = pattern.match(str)\n",
    "            if match:\n",
    "                resp = random.choice(response)\n",
    "                resp = self._wildcards(resp, match)\n",
    "                if resp[-2:] == '?.':\n",
    "                    resp = resp[:-2] + '.'\n",
    "                if resp[-2:] == '??':\n",
    "                    resp = resp[:-2] + '?'\n",
    "                if callback: # eventually: if callable(callback):\n",
    "                    callback(match)\n",
    "                return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>IEX</td>\n",
       "      <td>IDEX Corporation</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery</td>\n",
       "      <td>Lake Forest, Illinois</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>832101</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>MCO</td>\n",
       "      <td>Moody's Corp</td>\n",
       "      <td>reports</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Financial Exchanges &amp; Data</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1059556</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>reports</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Insurance Brokers</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1140536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>WRK</td>\n",
       "      <td>WestRock</td>\n",
       "      <td>reports</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Paper Packaging</td>\n",
       "      <td>Richmond, Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1636023</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>SBUX</td>\n",
       "      <td>Starbucks Corp.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829224</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security SEC filings             GICS Sector  \\\n",
       "244  IEX    IDEX Corporation      reports     Industrials              \n",
       "326  MCO    Moody's Corp          reports     Financials               \n",
       "494  WLTW   Willis Towers Watson  reports     Financials               \n",
       "490  WRK    WestRock              reports     Materials                \n",
       "425  SBUX   Starbucks Corp.       reports     Consumer Discretionary   \n",
       "\n",
       "              GICS Sub Industry   Headquarters Location Date first added  \\\n",
       "244  Industrial Machinery        Lake Forest, Illinois   2019-08-09        \n",
       "326  Financial Exchanges & Data  New York, New York      NaN               \n",
       "494  Insurance Brokers           London, United Kingdom  2016-01-05        \n",
       "490  Paper Packaging             Richmond, Virginia      NaN               \n",
       "425  Restaurants                 Seattle, Washington     NaN               \n",
       "\n",
       "         CIK Founded  \n",
       "244  832101   1988    \n",
       "326  1059556  1909    \n",
       "494  1140536  NaN     \n",
       "490  1636023  2015    \n",
       "425  829224   1971    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "df=table[0]\n",
    "newdf=df[[\"Symbol\",\"Security\"]]\n",
    "dic=newdf.set_index('Symbol')['Security'].to_dict()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_stock_trend_complete(match):\n",
    "    s=match.groups()[0]\n",
    "    d=pd.DataFrame()\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "        fig = px.line(d, x=\"Date\", y=\"Close\",\n",
    "                      labels={'Close':'Closing Stock Price'}, \n",
    "                      template='plotly_dark',\n",
    "                     color_discrete_sequence=[ \"aqua\"],\n",
    "                      title=\"Closing Stock Price for the Current Year for \"+str(s)\n",
    "                     )\n",
    "        fig.write_image(\"images/\"+ str(s) +\".png\")    \n",
    "        fig.write_image(\"images/\"+ str(s) +\".png\")    \n",
    "        return fig.show()\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_yearly_stock_trend_complete(match):\n",
    "    s=match.groups()[0]\n",
    "    d=pd.DataFrame()\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='5y',interval='1wk').reset_index())\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='5y',interval='1wk').reset_index())\n",
    "        fig = px.line(d, x=\"Date\", y=\"Close\",\n",
    "                      labels={'Close':'Closing Stock Price'}, \n",
    "                      template='plotly_dark',\n",
    "                     color_discrete_sequence=[ \"aqua\"],\n",
    "                      title=\"Closing Stock Price for the Last 5 years for \"+str(s)\n",
    "                     )\n",
    "        fig.write_image(\"images/\"+ str(s) +\".png\")    \n",
    "        fig.write_image(\"images/\"+ str(s) +\".png\")    \n",
    "        return fig.show()\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_stock_trend_complete(match):\n",
    "    s=match.groups()[0]\n",
    "    d=pd.DataFrame()\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1mo',interval='1d').reset_index())\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1mo',interval='1d').reset_index())\n",
    "        fig = px.line(d, x=\"Date\", y=\"Close\",\n",
    "                      labels={'Close':'Closing Stock Price'}, \n",
    "                      template='plotly_dark',\n",
    "                     color_discrete_sequence=[ \"aqua\"],\n",
    "                      title=\"Closing Stock Price for the Current Year for \"+str(s)\n",
    "                     )\n",
    "        print(fig.show())\n",
    "        fig.write_image(\"images/\"+ str(s) +\".png\")    \n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_d(match):\n",
    "    s=match.groups()[0]\n",
    "    wordcloud = WordCloud().generate(s)\n",
    "    fig, axes= plt.subplots(figsize=(20,12),clear=True)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.show()\n",
    "    wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividends(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                st=\"Dividends info of \"+str(v).upper()+\" is:\\n\"+ str(m.dividends)\n",
    "                print(st)\n",
    "                message = client.messages \\\n",
    "                .create(\n",
    "                     body=st,\n",
    "                     from_='+12513513792',\n",
    "                     to='+12098220910'\n",
    "                 )\n",
    "\n",
    "                message.sid\n",
    "                 \n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                st=\"Dividends info of \"+str(v).upper()+\" is:\\n\"+ str(m.dividends)\n",
    "                message = client.messages \\\n",
    "                .create(\n",
    "                     body=st,\n",
    "                     from_='+12513513792',\n",
    "                     to='+12098220910'\n",
    "                 )\n",
    "\n",
    "                message.sid\n",
    "                #print(\"check your messages\")\n",
    "\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"actions info of \"+str(v).upper()+\" is:\\n\"+ str(m.actions))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"actions info of \"+str(v).upper()+\" is: \\n\"+ str(m.actions))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def options(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"options info of \"+str(v).upper()+\" is:\\n\"+ str(m.options))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"options info of \"+str(v).upper()+\" is: \\n\"+ str(m.options))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isin(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"International Securities Identification Number of \"+str(v).upper()+\" is:\\n\"+ str(m.isin))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"International Securities Identification Number of \"+str(v).upper()+\" is: \\n\"+ str(m.isin))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financials(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Financials info of \"+str(v).upper()+\" is: \\n\"+ str(m.financials))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Financials of \"+str(v).upper()+\" is: \\n\"+ str(m.financials))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_holders(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Major Holders info of \"+str(v).upper()+\" is: \\n\"+ str(m.major_holders))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                df=pd.DataFrame(m.major_holders,columns=['Percentage','Held_By'])\n",
    "                print(\"Major Holders info of \"+str(v).upper()+\" is: \\n\"+ str(m.major_holders))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_financials(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly Financials info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_financials))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly Financials of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_financials))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_sheet(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Balance Sheet info of \"+str(v).upper()+\" is: \\n\"+ str(m.balance_sheet))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Balance Sheet info of \"+str(v).upper()+\" is: \\n\"+ str(m.balance_sheet))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cashflow(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"cashflow info of \"+str(v).upper()+\" is: \\n\"+ str(m.cashflow))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"cashflow info of \"+str(v).upper()+\" is: \\n\"+ str(m.cashflow))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earnings(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"earnings info of \"+str(v).upper()+\" is: \\n\"+ str(m.earnings))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"earnings info of \"+str(v).upper()+\" is: \\n\"+ str(m.earnings))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sustainability(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"sustainability info of \"+str(v).upper()+\" is: \\n\"+ str(m.sustainability))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"sustainability info of \"+str(v).upper()+\" is: \\n\"+ str(m.sustainability))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                recom=pd.DataFrame(m.recommendations).reset_index()\n",
    "                recom.to_csv(\"recommendations_of_\"+str(v).upper()+\".csv\",index=False)\n",
    "                print(\"recommendations info of \"+str(v).upper()+\" is: \\n\"+ str(m.recommendations))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                recom=pd.DataFrame(m.recommendations).reset_index()\n",
    "                recom.to_csv(\"recommendations_of_\"+str(v).upper()+\".csv\",index=False)\n",
    "                print(\"recommendations info of \"+str(v).upper()+\" is: \\n\"+ str(m.recommendations))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calendar(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"calendar info of \"+str(v).upper()+\" is: \\n\"+ str(m.calendar))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"calendar info of \"+str(v).upper()+\" is: \\n\"+ str(m.calendar))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_cashflow(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly cashflow info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_cashflow))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly cashflow info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_cashflow))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_earnings(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly earnings info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_earnings))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly earnings info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_earnings))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_balance_sheet(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly Balance Sheet info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_balance_sheet))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Quarterly Balance Sheet info of \"+str(v).upper()+\" is: \\n\"+ str(m.quarterly_balance_sheet))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def institutional_holders(match):\n",
    "    s=match.groups()[0]\n",
    "    try:   \n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Institutional Holders info of \"+str(v).upper()+\" is: \\n\"+ str(m.institutional_holders))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Institutional Holders info of \"+str(v).upper()+\" is: \\n\"+ str(m.institutional_holders))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Splits info of \"+str(v).upper()+\" is: \\n\"+ str(m.splits))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                m=yf.Ticker(k)\n",
    "                print(\"Splits info of \"+str(v).upper()+\" is: \\n\"+ str(m.splits))\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *\n",
    "def analyst_info(match):\n",
    "    s=match\n",
    "    for (k,v) in dic.items():\n",
    "        #\n",
    "        if re.compile(s.lower()).match(v.lower()):\n",
    "            df=pd.DataFrame(get_analysts_info(k))\n",
    "            print(df.head(2))\n",
    "            #print(\"Analyst info of \"+str(v).upper()+\" is: \\n\"+ str(get_analysts_info(k)))\n",
    "        elif re.compile(s.lower()).match(k.lower()):\n",
    "            print(\"Analyst info of \"+str(v).upper()+\" is: \\n\"+ str(get_analysts_info(k)))\n",
    "            #df=pd.DataFrame.from_dict(get_analysts_info(k),columns=['Earnings Estimate',''])\n",
    "            #print(df.head(2))\n",
    "            \n",
    "#analyst_info('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *\n",
    "def analyst_info(match):\n",
    "    s=match.groups()[0]\n",
    "    print(s)\n",
    "    for (k,v) in dic.items():\n",
    "        if re.compile(s.lower()).match(v.lower()):\n",
    "            print(\"Analyst info of \"+str(v).upper()+\" is: \\n\"+ str(get_analysts_info(k)))\n",
    "        elif re.compile(s.lower()).match(k.lower()):\n",
    "            print(\"Analyst info of \"+str(v).upper()+\" is: \\n\"+ str(get_analysts_info(k)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_losers(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        if s:\n",
    "            df=pd.DataFrame(get_day_losers())\n",
    "            df.to_csv('stockbot/day_losers.csv',index=False)\n",
    "            #wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n",
    "\n",
    "            print(df.head())\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_gainers(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        if s:\n",
    "            df=pd.DataFrame(get_day_gainers())\n",
    "            df.to_csv('stockbot/day_gainers.csv',index=False)\n",
    "            #wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n",
    "\n",
    "            print(df.head())\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_most_active(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        if s:\n",
    "            df=pd.DataFrame(get_day_most_active())\n",
    "            df.to_csv('stockbot/day_most_active.csv',index=False)\n",
    "            #wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n",
    "\n",
    "            st=df.head()\n",
    "            print(st)\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_stats(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                print(\"Stats info of \"+str(v).upper()+\" is: \\n\"+ str(get_stats(k)))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                print(\"Stats info of \"+str(v).upper()+\" is: \\n\"+ str(get_stats(k)))\n",
    "            df=pd.DataFrame(get_stats())\n",
    "            df.to_csv('stockbot/day_stats.csv',index=False)\n",
    "            #wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n",
    "\n",
    "            st=df.head()\n",
    "            print(st)\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_stats_valuation(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                print(\"Stats info of \"+str(v).upper()+\" is: \\n\"+ str(get_stats_valuation(k)))\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                print(\"Stats info of \"+str(v).upper()+\" is: \\n\"+ str(get_stats_valuation(k)))\n",
    "            df=pd.DataFrame(get_stats())\n",
    "            df.to_csv('stockbot/day_stats.csv',index=False)\n",
    "            #wordcloud.to_file(\"wordcloud_images/\"+ str(s[0:7]) +\".png\")\n",
    "\n",
    "            st=df.head()\n",
    "            print(st)\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            engine.stop()    \n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_stock_compare(match):\n",
    "    try:\n",
    "        s=match.groups()[0]\n",
    "        s1=match.groups()[1]\n",
    "        s2=match.groups()[2]\n",
    "        s3=match.groups()[3]\n",
    "        s4=match.groups()[4]\n",
    "        d=pd.DataFrame()\n",
    "        d1=pd.DataFrame()    \n",
    "        d2=pd.DataFrame()    \n",
    "        d3=pd.DataFrame()\n",
    "        d4=pd.DataFrame()\n",
    "        df12=pd.DataFrame()\n",
    "        d123=pd.DataFrame()    \n",
    "        d1234=pd.DataFrame()    \n",
    "        d12345=pd.DataFrame()\n",
    "\n",
    "\n",
    "        df_vis=pd.DataFrame()\n",
    "        import matplotlib.animation as ani\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                d=d.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "                d['companyName']=v\n",
    "                #print(d.info())\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s1.lower()).match(v.lower()):\n",
    "                d1=d1.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s1.lower()).match(k.lower()):\n",
    "                d1=d1.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "                d1['companyName']=v\n",
    "\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s2.lower()).match(v.lower()):\n",
    "                d2=d2.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s2.lower()).match(k.lower()):\n",
    "                d2=d2.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "                d2['companyName']=v\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s3.lower()).match(v.lower()):\n",
    "                d3=d3.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s3.lower()).match(k.lower()):\n",
    "                d3=d3.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "                d3['companyName']=v            \n",
    "\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s4.lower()).match(v.lower()):\n",
    "                d4=d4.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "            elif re.compile(s4.lower()).match(k.lower()):\n",
    "                d4=d4.append(yf.Ticker(k).history(period='1y',interval='1d').reset_index())\n",
    "                d4['companyName']=v\n",
    "\n",
    "                newlist=[d,d1,d2,d3,d4]\n",
    "                df1234=pd.concat(newlist,ignore_index=True)\n",
    "                df_vis=df_vis.append(df1234)\n",
    "        df_vis['companyName']=df_vis['companyName'].fillna('Something else')\n",
    "        fig4 = px.line(df_vis, x=\"Date\", y=\"Close\",color=\"companyName\",\n",
    "                      labels={'Close':'Closing Stock Price'}, \n",
    "                      template='plotly_dark',\n",
    "                      title=\"Closing Stock Price for the Current Year for \"\n",
    "                     )\n",
    "        fig4.write_image(\"images/new\" +\".png\")    \n",
    "        print(fig4.show())\n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.getProperty('voice')\n",
    "engine.setProperty('voice', '1')\n",
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(match):\n",
    "    txt=match.groups()[0]\n",
    "    senti = SentimentIntensityAnalyzer()\n",
    "    try:\n",
    "        if (fuzz.token_set_ratio(txt,\"document\")>50) or (fuzz(txt,\"file\")>50):\n",
    "            file_path=input(\"enter file path: \")\n",
    "            f= open(file_path)\n",
    "            f1=str(f.readlines())\n",
    "            sia=senti.polarity_scores(f1)\n",
    "            print(['({0}: {1})'.format(k, sia[k]) for k in sia])    \n",
    "            wordcloud = WordCloud().generate(f1)\n",
    "            fig, axes= plt.subplots(figsize=(20,12),clear=True)\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.show()\n",
    "            wordcloud.to_file(\"wordcloud_images/img.png\")\n",
    "\n",
    "             #From the Vader Library, we will perform both sentiment and intensity analysis\n",
    "        else:\n",
    "            f1=input(\"Enter the text for performing Text Analytics: \")\n",
    "            sia = senti.polarity_scores(f1)\n",
    "            print(['({0}: {1})'.format(k, sia[k]) for k in sia])\n",
    "            wordcloud = WordCloud().generate(f1)\n",
    "            fig, axes= plt.subplots(figsize=(20,12),clear=True)\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.show()\n",
    "            wordcloud.to_file(\"wordcloud_images/img.png\")\n",
    "    except Exception as e: # work on python 3.x\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math(match):\n",
    "    s=match.groups()[0]\n",
    "    try:\n",
    "        op=input(\"What operation would you like to do?\")\n",
    "        while op==\"add\":\n",
    "            a=input(\"Enter the first number: \")\n",
    "            b=input(\"Enter the second number: \")\n",
    "            print(a+b)\n",
    "    except Exception as e: # work on python 3.x\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'us', 'sa'}\n"
     ]
    }
   ],
   "source": [
    "c=['ae' ,'ar' ,'at' ,'au' ,'be' ,'bg' ,'br' ,'ca' ,'ch' ,'cn' ,'co' ,'cu' ,'cz' ,'de' ,'eg' ,'fr' ,'gb' ,'gr' ,'hk' ,'hu' ,'id' ,'ie' ,'il' ,'in' ,'it' ,'jp' ,'kr' ,'lt' ,'lv' ,'ma' ,'mx' ,'my' ,'ng' ,'nl' ,'no' ,'nz' ,'ph' ,'pl' ,'pt' ,'ro' ,'rs' ,'ru' ,'sa' ,'se' ,'sg' ,'si' ,'sk' ,'th' ,'tr' ,'tw' ,'ua' ,'us' ,'ve' ,'za']\n",
    "cat=['business', 'entertainment', 'general health' ,'science', 'sports', 'technology']\n",
    "category='business'\n",
    "country='usa'\n",
    "cat_miss=[]\n",
    "country_miss=[]\n",
    "if category in cat and country in c:   \n",
    "    top_headlines = newsapi.get_top_headlines(category=category,language='en',country=country)\n",
    "    top_headlines=json_normalize(top_headlines['articles'])\n",
    "    top_headlines=top_headlines.head()\n",
    "    top_headlines['country']=i\n",
    "    top_headlines['category']=j\n",
    "    print(top_headlines.head(1))\n",
    "elif category not in cat and country in c:\n",
    "    for j in cat:\n",
    "        if (fuzz.partial_ratio(category,j)>50):\n",
    "            cat_miss.append(j)\n",
    "    d=set(cat_miss)\n",
    "    print(str(d))\n",
    "elif country not in c and category in cat:\n",
    "    for i in c:\n",
    "        if (fuzz.partial_ratio(country,i)>70):\n",
    "            country_miss.append(i)\n",
    "    d1=set(country_miss)\n",
    "    print(str(d1))\n",
    "else:\n",
    "    d1=set(country_miss)\n",
    "    d=set(cat_miss)\n",
    "    if len(d)==1:\n",
    "        print(\"Could not find that category, did you mean this?\"+str(d))\n",
    "    else:\n",
    "        print(\"Could not find that category, did you mean any of these?\"+str(d))       \n",
    "    if len(d1)==1:\n",
    "        print(\"Could not find that country, did you mean this?\"+str(d1))\n",
    "    else:\n",
    "        print(\"Could not find that country, did you mean any of these?\"+str(d1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock(match):\n",
    "    s=match.groups()[0]\n",
    "    d=[]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                st=\"Current stock price of \"+str(v).upper()+\" is: \"+ str(np.round(si.get_live_price(k),2))\n",
    "                print(st)\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                st=\"Current stock price of \"+str(v).upper()+\" is: \"+ str(np.round(si.get_live_price(k),2))\n",
    "                print(st)\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "           \n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock(match):\n",
    "    s=match.groups()[0]\n",
    "    d=[]\n",
    "    try:\n",
    "        for (k,v) in dic.items():\n",
    "            if re.compile(s.lower()).match(v.lower()):\n",
    "                st=\"Current stock price of \"+str(v).upper()+\" is: \"+ str(np.round(si.get_live_price(k),2))\n",
    "                print(st)\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "            elif re.compile(s.lower()).match(k.lower()):\n",
    "                st=\"Current stock price of \"+str(v).upper()+\" is: \"+ str(np.round(si.get_live_price(k),2))\n",
    "                print(st)\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "           \n",
    "    except Exception as e: # work on python 3.x\n",
    "        engine.say(str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_headlines(match):\n",
    "    try:\n",
    "        #start = time.time()\n",
    "        category=match.groups()[1]\n",
    "        country=match.groups()[0]\n",
    "        c=['ae' ,'ar' ,'at' ,'au' ,'be' ,'bg' ,'br' ,'ca' ,'ch' ,'cn' ,'co' ,'cu' ,'cz' ,'de' ,'eg' ,'fr' ,'gb' ,'gr' ,'hk' ,'hu' ,'id' ,'ie' ,'il' ,'in' ,'it' ,'jp' ,'kr' ,'lt' ,'lv' ,'ma' ,'mx' ,'my' ,'ng' ,'nl' ,'no' ,'nz' ,'ph' ,'pl' ,'pt' ,'ro' ,'rs' ,'ru' ,'sa' ,'se' ,'sg' ,'si' ,'sk' ,'th' ,'tr' ,'tw' ,'ua' ,'us' ,'ve' ,'za']\n",
    "        cat=['business', 'entertainment', 'general health' ,'science', 'sports', 'technology']\n",
    "        #category='busine'\n",
    "        #country='usa'\n",
    "        cat_miss=[]\n",
    "        country_miss=[]\n",
    "        if category in cat and country in c:\n",
    "            \n",
    "            top_headlines = newsapi.get_top_headlines(category=category,language='en',country=country)\n",
    "            top_headlines=json_normalize(top_headlines['articles'])\n",
    "            top_headlines=top_headlines.head()\n",
    "            top_headlines['country']=country\n",
    "            top_headlines['category']=category\n",
    "            newdf=top_headlines[[\"title\",\"url\"]]\n",
    "            dic=newdf.set_index('title')['url'].to_dict()\n",
    "            engine.say(\"Here are some of the top articles\")\n",
    "            engine.runAndWait()\n",
    "            news_list=[]\n",
    "            for (k,v) in dic.items():\n",
    "                start = time.time()\n",
    "                engine.say(k)\n",
    "                engine.say('You can find more information here:')\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "                engine.say(k+\"\\n\"+v)\n",
    "                message = client.messages \\\n",
    "                .create(\n",
    "                     body=k+\"\\n\"+v,\n",
    "                     from_='+12513513792',\n",
    "                     to='+12098220910')\n",
    "                message.sid\n",
    "                end = time.time()\n",
    "        elif category not in cat and country in c:\n",
    "            for j in cat:\n",
    "                if (fuzz.partial_ratio(category,j)>50):\n",
    "                    cat_miss.append(j)\n",
    "            d=set(cat_miss)\n",
    "            if len(d)==1:\n",
    "                print(\"Could not find that category, did you mean this?\"+str(d))\n",
    "            else:\n",
    "                print(\"Could not find that category, did you mean any of these?\"+str(d))    \n",
    "        elif country not in c and category in cat:\n",
    "            for i in c:\n",
    "                if (fuzz.partial_ratio(country,i)>70):\n",
    "                    country_miss.append(i)\n",
    "            d1=set(country_miss)\n",
    "            if len(d1)==1:\n",
    "                print(\"Could not find that country, did you mean this?\"+str(d1))\n",
    "            else:\n",
    "                print(\"Could not find that country, did you mean any of these?\"+str(d1))\n",
    "        else:\n",
    "            if len(d)==1:\n",
    "                print(\"Could not find that category, did you mean this?\"+str(d))\n",
    "            else:\n",
    "                print(\"Could not find that category, did you mean any of these?\"+str(d))       \n",
    "            if len(d1)==1:\n",
    "                print(\"Could not find that country, did you mean this?\"+str(d1))\n",
    "            else:\n",
    "                print(\"Could not find that country, did you mean any of these?\"+str(d1))\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "    except Exception as e:\n",
    "        engine.say(str(e))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\"(Hi|Hello|Hey) I'm (.*)\", [\"\"\"Hey %1, What can I do for you? \\nYou can ask me for Stocks information, \n",
    "    ask me to generate wordclouds or for the latest news\n",
    "                                 \"\"\"], None],\n",
    "   #[\"number (.*)+(.*)\",[\"nothing\"],math],\n",
    "#    Enter stock symbol for the below 3 cases: To test it out, you can type in the chat \"open Apple stock\" or \"open AAPL stock\"\n",
    "    # you can type both stock symbol or company name.\n",
    "    [\"open (.*) live Stock\", [\"\"], stock],\n",
    "    # for this below case, type \"open Apple yearly\" to get stock trend for the current year for Apple\n",
    "    [\"open (.*) Yearly\", [\"Yearly stock trend for \" + \"%1\".upper()], yearly_stock_trend_complete],\n",
    "    [\"compare (.*), (.*), (.*), (.*), (.*)\", [\"Yearly stock trend for \" + \"%1\".upper()+\", %2\".upper()+\", %3\".upper()+\", %4\".upper()+\", %5\".upper()], yearly_stock_compare],\n",
    "   \n",
    "    [\"open (.*) 5\", [\"Five Yearly stock trend for \" + \"%1\".upper()], five_yearly_stock_trend_complete],\n",
    " # for this below case, type \"open Apple monthly\" to get stock trend for the current month for Apple\n",
    "    [\"open (.*) Monthly\", [\"Monthy stock trend for \" + \"%1\".upper()], monthly_stock_trend_complete],\n",
    "# Enter Text to perform Text Analytics. First type text type: document/text. If document enter document path else enter text \n",
    "    [\"perform TA of (.*)\", [\"\"], sentiment],\n",
    "    [\"generate wordclouds of (.*)\", [\"\"], sentiment],\n",
    "    \n",
    "    #[\"news (.*)\",[\"Here's the latest news \\n\"], general_headlines],\n",
    " #Get the top headlines: enter country followed by category   \n",
    "    [\"(.*) (.*) news\", [\"\"], top_headlines],\n",
    "     [\"open (.*) dividends\", [\"\"], dividends],\n",
    "    [\"open (.*) actions\", [\"\"], actions],\n",
    "      [\"open (.*) sustainability\", [\"\"], sustainability],\n",
    "    [\"open (.*) recommendations\", [\"\"], recommendations],\n",
    "    [\"open (.*) analyst info\", [\"\"], analyst_info],\n",
    "  \n",
    "  [\"open (.*) options\", [\"\"], options],\n",
    "  [\"open (.*) isin\", [\"\"], isin],\n",
    "  \n",
    "    [\"open (.*) splits\", [\"\"], splits],\n",
    "    [\"open (.*) financials\", [\"\"], financials],\n",
    "    [\"open (.*) quarterly financials\", [\"\"], quarterly_financials],\n",
    "[\"open (.*) balance sheet\", [\"\"], balance_sheet],\n",
    "    [\"open (.*) quarterly balance sheet\", [\"\"], quarterly_balance_sheet],\n",
    "[\"open (.*) earnings\", [\"\"], earnings],\n",
    "    [\"open (.*) quarterly earnings\", [\"\"], quarterly_earnings],\n",
    "    [\"open (.*) cashflow\", [\"\"], cashflow],\n",
    "    [\"open (.*) quarterly cashflow\", [\"\"], cashflow],\n",
    "[\"open (.*) calendar\", [\"\"], calendar],\n",
    "\n",
    " [\"open (.*) gainers\", [\"\"], day_gainers],\n",
    " [\"open (.*) losers\", [\"\"], day_losers],\n",
    " [\"open (.*) stats\", [\"\"], day_stats],\n",
    " [\"open (.*) stats valuation\", [\"\"], day_stats_valuation],\n",
    "     [\"open (.*) day most active\", [\"\"], get_day_most_active],\n",
    " [\"open (.*) losers\", [\"\"], day_losers],\n",
    "    [\"open (.*) major holders\", [\"\"], major_holders],\n",
    "    [\"open (.*) institutional holders\", [\"\"], institutional_holders],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings! My name is Muku, What is yours?.\n",
      ">us business news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BSTR.__del__ at 0x0000022BB7DABA68>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mukun\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\comtypes\\__init__.py\", line 1005, in __del__\n",
      "    def __del__(self, _free=windll.oleaut32.SysFreeString):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.524858236312866\n",
      "\n",
      ">open apple stock\n",
      "None\n",
      ">open apple live stock\n",
      "Current stock price of APPLE INC. is: 338.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Greetings! My name is Muku, What is yours?.\")\n",
    "    Chatbot = Muku_Chat(pairs, reflections)\n",
    "    #Chatbot.respond(x)\n",
    "    Chatbot.converse()\n",
    "if __name__==\"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/May/2020 01:01:03] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/May/2020 01:01:23] \"\u001b[37mGET /get?msg=open%20apple%20live%20stock HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stock price of APPLE INC. is: 319.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/May/2020 01:19:22] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/May/2020 01:19:34] \"\u001b[37mGET /get?msg=open%20apple%20live%20stock HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stock price of APPLE INC. is: 319.23\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request,redirect\n",
    "import os\n",
    "app = Flask(__name__)\n",
    "#app.config[\"DEBUG\"] = True\n",
    "@app.route(\"/\")\n",
    "def home():    \n",
    "    return render_template('home.html') \n",
    "@app.route(\"/get\")\n",
    "\n",
    "def chat():\n",
    "    x = request.args.get('msg')\n",
    "    Chatbot = Muku_Chat(pairs, reflections)\n",
    "    return Chatbot.respond(x)\n",
    "if __name__ == \"__main__\":    \n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('have', 'free'),\n",
       " ('free', 'hours'),\n",
       " ('hours', 'and'),\n",
       " ('and', 'love'),\n",
       " ('love', 'children?'),\n",
       " ('children?', 'drive'),\n",
       " ('drive', 'kids'),\n",
       " ('kids', 'to'),\n",
       " ('to', 'school,'),\n",
       " ('school,', 'soccer'),\n",
       " ('soccer', 'practice'),\n",
       " ('practice', 'and'),\n",
       " ('and', 'other'),\n",
       " ('other', 'activities.')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Have free hours and love children? Drive kids to school, soccer practice and other activities.\"\"\"\n",
    "w=sentence.lower().split(' ')\n",
    "lis1t=[]\n",
    "for i in range(len(w)-1):\n",
    "    lis1t.append((w[i],w[i+1]))\n",
    "lis1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
